#include "cuda_runtime.h"
#include "device_launch_parameters.h"
#include <stdio.h>
#include <stdlib.h>

#define BLOCK_SIZE 16 

// тип, который будут иметь элементы матриц
#define BASE_TYPE int 
// функция перемножения матриц
__global__ void matrixMult(const BASE_TYPE* A, const BASE_TYPE* B, BASE_TYPE* C, int Acols, int Bcols)
{
	int i0 = Acols * (blockDim.y * blockIdx.y + threadIdx.y);
	int j0 = blockDim.x * blockIdx.x + threadIdx.x;
	BASE_TYPE sum = 0;
	for (int k = 0; k < Acols; k++)
			sum += A[i0 + k] * B[k * Bcols + j0];
	int ind = Bcols * (blockDim.y * blockIdx.y + threadIdx.y) + blockDim.x * blockIdx.x + threadIdx.x;
	C[ind] = sum;
}

int toMultiple(int a, int b) {
	int mod = a % b;
	if (mod != 0) {
		mod = b - mod;
		return a + mod;
	}
	return a;
}

int main()
{
	// количество строк и столбцов матрицы
	int Arows = 5;
	int Acols = 5;
	int Brows = Acols;
	int Bcols = 5;

	Arows = toMultiple(Arows, BLOCK_SIZE);
	printf("Arows = %d\n", Arows);

	Acols = toMultiple(Acols, BLOCK_SIZE);
	printf("Acols = %d\n", Acols);
	Brows = toMultiple(Brows, BLOCK_SIZE);
	printf("Brows = %d\n", Brows);

	Bcols = toMultiple(Bcols, BLOCK_SIZE);
	printf("Bcols = %d\n", Bcols);

	//размерность
	size_t Asize = Arows * Acols * sizeof(BASE_TYPE);
	size_t Bsize = Brows * Bcols * sizeof(BASE_TYPE);
	size_t Csize = Arows * Bcols * sizeof(BASE_TYPE);
	// переменные на GPU
	BASE_TYPE* h_A = (BASE_TYPE*)malloc(Asize);
	BASE_TYPE* h_B = (BASE_TYPE*)malloc(Bsize);
	BASE_TYPE* h_C0 = (BASE_TYPE*)malloc(Csize);
	BASE_TYPE* h_C1 = (BASE_TYPE*)malloc(Csize);
	
	// инициализация переменных
	srand(time(0));

	for (int i = 0; i < Arows * Acols; ++i) {
		h_A[i] = rand() / (BASE_TYPE)RAND_MAX;
	}
	for (int i = 0; i < Brows * Bcols; ++i) {
		h_B[i] = rand() / (BASE_TYPE)RAND_MAX;
	}
	// выделяем память на GPU
	BASE_TYPE* d_A = NULL;
	cudaMalloc((void**)&d_A, Asize);

	BASE_TYPE* d_B = NULL;
	cudaMalloc((void**)&d_B, Bsize);

	BASE_TYPE* d_C0 = NULL;
	cudaMalloc((void**)&d_C0, Csize);

	BASE_TYPE* d_C1 = NULL;
	cudaMalloc((void**)&d_C1, Csize);
	// копирование информации с CPU на GPU
	cudaMemcpy(d_A, h_A, Asize, cudaMemcpyHostToDevice);
	cudaMemcpy(d_B, h_B, Bsize, cudaMemcpyHostToDevice);

	dim3 threadsPerBlock = dim3(BLOCK_SIZE, BLOCK_SIZE);
	dim3 blocksPerGrid = dim3(Bcols / BLOCK_SIZE, Arows / BLOCK_SIZE);
	// вызов ядра
	matrixMult << <blocksPerGrid, threadsPerBlock >> > (d_A, d_B, d_C0, Acols, Bcols);
	matrixMult << <blocksPerGrid, threadsPerBlock >> > (d_B, d_A, d_C1, Acols, Bcols);
	// копирование результата работы ядра с GPU на CPU
	cudaMemcpy(h_C0, d_C0, Csize, cudaMemcpyDeviceToHost);
	cudaMemcpy(h_C1, d_C1, Csize, cudaMemcpyDeviceToHost);
	
	//вывод результата
	bool b = true;
	for (int k = 0; k < Acols; k++) {
		if (h_C0[k] != h_C1[k])
			b = false;
	}
	if (b)
		printf("Success!");
	else
		printf("FAIL!");

	// очищение памяти на GPU
	cudaFree(d_A);
	cudaFree(d_B);
	cudaFree(d_C0);
	cudaFree(d_C1);
	free(h_A);
	free(h_B);
	free(h_C0);
	free(h_C1);
	return 0;
}
